{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iT9LtjAmc5Yf",
   "metadata": {
    "id": "iT9LtjAmc5Yf"
   },
   "source": [
    "`detailed_node_and_edge_features.ipynb`의 주된 역할은 다음과 같습니다:\n",
    "\n",
    "1. **OSM으로부터 그래프 불러오기**  \n",
    "   - 특정 도시의 도로망을 OSMnx로 로드해 GeoDataFrame(`gdf_nodes`, `gdf_edges`) 형태로 얻습니다.\n",
    "\n",
    "2. **사고 데이터와 그래프 노드 매핑**  \n",
    "   - US-Accidents 데이터의 위경도 좌표를 `nearest_nodes()`로 가장 가까운 OSM 노드에 매핑해, 각 노드에 사고 건수(`accident_cnt`)와 평균 심각도(`severity`) 정보를 연결합니다.\n",
    "\n",
    "3. **노드 특성 추출 및 전처리**  \n",
    "   - 논문 Table 2에 정의된 노드 특성들(`highway`, `street_count` 등)을 선택하고, `get_dummies`로 one-hot 인코딩해 `features` 매트릭스를 만듭니다.\n",
    "   - 최종적으로 모델 입력용 노드 피처 행렬의 크기(shape)와 컬럼명을 화면에 출력해서 “이렇게 생겼다”고 검증합니다.\n",
    "\n",
    "4. **엣지 특성 추출 및 전처리**  \n",
    "   - 엣지 GeoDataFrame에서 `length`, `lanes`, `maxspeed`, `bridge`, `oneway`, `highway` 등을 선별하고, 결측치·리스트 타입을 적절히 처리한 뒤 one-hot 인코딩합니다.\n",
    "   - `edge_attrs` 매트릭스로 만들어 모델 입력용 엣지 피처 행렬의 크기와 컬럼 구성을 확인합니다.\n",
    "\n",
    "5. **디버깅 및 검증**  \n",
    "   - “nearest_nodes 버그 체크”, 불완전한 카테고리 처리, 누락된 속성 예외 처리 로직 등을 포함해, 실제 전처리 코드가 논문에 맞게 정확히 동작하는지 단계별로 점검합니다.\n",
    "\n",
    "요약하면, 이 노트북은 논문의 Section 4 “데이터 전처리” 중 “어떤 지리공간(geo-spatial) 피처가 노드/엣지 특성 행렬로 대응되는지”를 실제 코드로 추출·시각화·검증하는 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809444aa-68fe-4778-8807-01e55d4e597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ujson as json   # 빠른 JSON 파싱\n",
    "import os\n",
    "\n",
    "base = Path('data')\n",
    "\n",
    "# ── 1) 모든 CSV/JSON 경로 한 번에 수집 ───────────────────────────────\n",
    "csv_paths  = list(base.rglob('*.csv'))\n",
    "json_paths = list(base.rglob('*.json'))\n",
    "\n",
    "# ── 2) V2X 로그 (CSV) 일괄 처리 ────────────────────────────────────\n",
    "# 실제 분석에 필요한 컬럼만 지정\n",
    "usecols = [\n",
    "    'ISSUE_DATE','LONGITUDE','LATITUDE','HEADING',\n",
    "    'SPEED','BRAKE_STATUS','ACC_SEC',\n",
    "    'CURRENT_LANE','VEHICLE_TYPE'\n",
    "]\n",
    "\n",
    "v2x_dfs = []\n",
    "for p in csv_paths:\n",
    "    # 경로 조각: ('9월','220911','C','A','9CD0DFDC','V_220911_C_A_9CD0DFDC_0001.csv')\n",
    "    parts = p.relative_to(base).parts\n",
    "    if len(parts) < 5:\n",
    "        continue\n",
    "\n",
    "    _, date_str, loc, tt, dev = parts[:5]\n",
    "    try:\n",
    "        date = pd.to_datetime(date_str, format='%y%m%d')\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    # 필요한 컬럼만 읽어들임\n",
    "    df = pd.read_csv(p, usecols=usecols, parse_dates=['ISSUE_DATE'])\n",
    "    df['Date']      = date\n",
    "    df['Location']  = loc\n",
    "    df['TimeType']  = tt\n",
    "    df['Device_ID'] = dev\n",
    "    v2x_dfs.append(df)\n",
    "\n",
    "if v2x_dfs:\n",
    "    v2x_df = pd.concat(v2x_dfs, ignore_index=True)\n",
    "    print(\"◾ V2X logs:\", v2x_df.shape)\n",
    "else:\n",
    "    print(\"⚠️ V2X logs 비어 있음!\")\n",
    "\n",
    "# ── 3) Annotations (JSON) 일괄 처리 ─────────────────────────────────\n",
    "anno_recs = []\n",
    "for p in json_paths:\n",
    "    parts = p.relative_to(base).parts\n",
    "    if len(parts) < 5:\n",
    "        continue\n",
    "\n",
    "    _, date_str, loc, tt, dev = parts[:5]\n",
    "    try:\n",
    "        date = pd.to_datetime(date_str, format='%y%m%d')\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    with open(p, 'r', encoding='utf-8') as fp:\n",
    "        j = json.load(fp)\n",
    "    anno_recs.append({\n",
    "        'Date':      date,\n",
    "        'Location':  loc,\n",
    "        'TimeType':  tt,\n",
    "        'Device_ID': dev,\n",
    "        'Turn':      j['Annotation']['Turn'],\n",
    "        'Lane':      j['Annotation']['Lane'],\n",
    "        'SpeedEvt':  j['Annotation']['Speed'],\n",
    "        'Hazard':    j['Annotation']['Hazard'],\n",
    "    })\n",
    "\n",
    "anno_df = pd.DataFrame(anno_recs)\n",
    "print(\"◾ Annotations:\", anno_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6N2lYg_P-NGs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6N2lYg_P-NGs",
    "outputId": "ce988ccf-fbb0-40eb-9721-ef544ea89222"
   },
   "outputs": [],
   "source": [
    "!pip install osmnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-prague",
   "metadata": {
    "id": "approximate-prague",
    "tags": []
   },
   "source": [
    "# 노드 및 엣지 특성\n",
    "- 이 노트북은 TAP(교통사고 예측)에서 사용되는 노드 특성 행렬에 대응하는 지리공간(geo-spatial) 특징들이 무엇인지 추가 정보를 제공합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-northwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "interesting-northwest",
    "outputId": "2a0244c3-fe12-4748-8b09-7bc5546735cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSMnx version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "np.random.seed(17)\n",
    "print(\"OSMnx version:\", ox.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2xpdgUyMFAvZ",
   "metadata": {
    "id": "2xpdgUyMFAvZ"
   },
   "outputs": [],
   "source": [
    "# 1) V2X 로그 불러오기\n",
    "v2x = pd.read_csv('datasets/v2x_logs.csv', parse_dates=['ISSUE_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RFRDnubRaRjt",
   "metadata": {
    "id": "RFRDnubRaRjt"
   },
   "outputs": [],
   "source": [
    "# 2) 좌표 → segment_id 매핑 함수\n",
    "def map_to_segment(lon, lat, G):\n",
    "    return ox.distance.nearest_edges(G, X=lon, Y=lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33015908-3d47-4798-b91b-96f4f53585b2",
   "metadata": {
    "id": "33015908-3d47-4798-b91b-96f4f53585b2"
   },
   "outputs": [],
   "source": [
    "# 3) 지역별 처리 (광주/세종)\n",
    "for loc_code, place_name in {'C':'Gwangju, South Korea','S':'Sejong, South Korea'}.items():\n",
    "    print(f\"=== {loc_code} ({place_name}) ===\")\n",
    "    G_city = ox.graph_from_place(place_name, simplify=True, network_type='drive')\n",
    "    gdf_nodes, gdf_edges = ox.graph_to_gdfs(G_city)\n",
    "\n",
    "    # 4) 노드 static 피처\n",
    "    node_static = gdf_nodes[['x','y','street_count','highway']].copy()\n",
    "    node_static['highway'].fillna('nan', inplace=True)\n",
    "    node_static = pd.concat([\n",
    "        node_static.drop('highway',axis=1),\n",
    "        pd.get_dummies(node_static.highway, prefix='hw')\n",
    "    ], axis=1)\n",
    "    x = torch.tensor(node_static.values, dtype=torch.float)\n",
    "    print(\" node_features:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf89c1a",
   "metadata": {
    "id": "7cf89c1a",
    "outputId": "ca2d29a3-096b-42c9-86da-cfcfbb23cff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current City: ('New York', 'New York')\n",
      "Node shape: (55292, 12) features: Index(['street_count', 'high_crossing', 'high_give_way',\n",
      "       'high_motorway_junction', 'high_nan', 'high_priority', 'high_stop',\n",
      "       'high_toll_gantry', 'high_traffic_signals',\n",
      "       'high_traffic_signals;crossing', 'high_turning_circle',\n",
      "       'high_turning_loop'],\n",
      "      dtype='object')\n",
      "Edge shape: (139463, 19) features: Index(['length', 'bridge', 'lanes', 'oneway_False', 'oneway_True',\n",
      "       'high_busway', 'high_living_street', 'high_motorway',\n",
      "       'high_motorway_link', 'high_primary', 'high_primary_link',\n",
      "       'high_residential', 'high_secondary', 'high_secondary_link',\n",
      "       'high_tertiary', 'high_tertiary_link', 'high_trunk', 'high_trunk_link',\n",
      "       'high_unclassified'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "    # 5) V2X 동적 엣지 피처\n",
    "    v2x['segment_id'] = v2x.apply(\n",
    "        lambda r: map_to_segment(r.LONGITUDE, r.LATITUDE, G_city),\n",
    "        axis=1\n",
    "    )\n",
    "    agg = {\n",
    "      'SPEED': ['mean','var'],\n",
    "      'BRAKE_STATUS': 'mean',\n",
    "      'ACC_SEC': ['mean','max','min'],\n",
    "      'CURRENT_LANE': lambda x: x.diff().abs().fillna(0).sum()\n",
    "    }\n",
    "    dyn = v2x.groupby('segment_id').agg(agg)\n",
    "    dyn.columns = ['_'.join(c) for c in dyn.columns]\n",
    "    dyn = dyn.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iEOdi8DCFJPX",
   "metadata": {
    "id": "iEOdi8DCFJPX"
   },
   "outputs": [],
   "source": [
    "    # 6) Static(OSM) + Dynamic(V2X) 병합\n",
    "    ed = gdf_edges.set_index(['u','v','key']).join(dyn, how='left').fillna(0)\n",
    "    static_attrs  = ['highway','oneway','length','bridge','lanes']\n",
    "    dynamic_attrs = list(dyn.columns)\n",
    "    ed = ed[static_attrs + dynamic_attrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7HT0xaMK_ATy",
   "metadata": {
    "id": "7HT0xaMK_ATy"
   },
   "outputs": [],
   "source": [
    "    # 7) 후처리\n",
    "    if 'bridge' in ed:\n",
    "        ed['bridge'] = LabelEncoder().fit_transform(ed['bridge'].fillna('nan'))\n",
    "    if 'lanes' in ed:\n",
    "        ed['lanes'] = LabelEncoder().fit_transform(ed['lanes'].astype(str).fillna('-1'))\n",
    "    ed = pd.concat([\n",
    "        ed,\n",
    "        pd.get_dummies(ed.highway, prefix='hw'),\n",
    "        pd.get_dummies(ed.oneway, prefix='ow')\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w5r254h4_DRV",
   "metadata": {
    "id": "w5r254h4_DRV"
   },
   "outputs": [],
   "source": [
    "    # 8) PyG Data\n",
    "    n2i = {nid:i for i,nid in enumerate(gdf_nodes.index)}\n",
    "    ei = torch.tensor([[n2i[u] for u,v in ed.index],\n",
    "                       [n2i[v] for u,v in ed.index]], dtype=torch.long)\n",
    "    ea = torch.tensor(ed.drop(['highway','oneway'],axis=1).values, dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=ei, edge_attr=ea)\n",
    "    print(\" edge_attr:\", ea.shape,\"\\n\", data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
