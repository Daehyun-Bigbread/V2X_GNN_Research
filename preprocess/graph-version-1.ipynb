{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c40322-84c6-4f2e-b459-e9e3c407644d",
   "metadata": {},
   "source": [
    "#### Parquet을 읽고 차량(VEHICLE_ID) 리스트, sensor 노드 매핑 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafc7933-2362-43a5-9187-8420e88f059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# (1) 모든 Parquet 파일을 하나로 읽어서 DataFrame으로 합치기\n",
    "# 보통 날짜별/장소별 Parquet이 분리되어 있으므로, rglob으로 재귀 탐색\n",
    "parquet_root = Path(\"data/processed_v2x\")\n",
    "all_parquets = sorted(parquet_root.rglob(\"*.parquet\"))\n",
    "\n",
    "# 리스트에 담았다가 한 번에 합칩니다. (메모리가 허용하는 선에서만 사용하세요.)\n",
    "df_list = []\n",
    "for p in all_parquets:\n",
    "    df_tmp = pd.read_parquet(p)\n",
    "    # Parquet 파일이라면 이미  \n",
    "    # 'timestamp', 'VEHICLE_ID', 'LONGITUDE', 'LATITUDE', 'SPEED', 'ACC_SEC', 'BRAKE_STATUS', 'period', 'date', 'location'\n",
    "    # 등이 포함되어 있을 것입니다.\n",
    "    df_list.append(df_tmp)\n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# (2) Vehicle_ID 목록 (고유 노드 개수) 구하기\n",
    "vehicle_ids = df_all[\"VEHICLE_ID\"].unique().tolist()\n",
    "N = len(vehicle_ids)\n",
    "\n",
    "# 각 VEHICLE_ID를 0..N-1 정수로 매핑\n",
    "vid2idx = {vid: i for i, vid in enumerate(vehicle_ids)}\n",
    "\n",
    "# (3) Node 별 “대표 위치”(위도, 경도) 구하기\n",
    "# 예: 데이터프레임에서 가장 첫 번째 기록(혹은 평균 위치 등) 하나를 뽑아서 static 피처로 쓰면 된다.\n",
    "rep = df_all.sort_values(\"timestamp\").groupby(\"VEHICLE_ID\").first().reset_index()\n",
    "# rep DataFrame 에는 각 vehicle_id당 대표 레코드가 들어 있어요.\n",
    "# 예를 들어 rep[\"LATITUDE\"], rep[\"LONGITUDE\"] 등을 static feature로 쓸 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc257c-81e1-4f2b-b3fe-f1c075b3cd6e",
   "metadata": {},
   "source": [
    "OSMnx로 그래프(도로망) 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deaf1009-2194-4027-a97a-79795847d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "# (1) 센서 대표 위치의 평균 위경도를 계산해서 중심점으로 잡기\n",
    "lat_center = rep[\"LATITUDE\"].mean()\n",
    "lon_center = rep[\"LONGITUDE\"].mean()\n",
    "\n",
    "# (2) 반경 1km짜리 도로망을 “drive” 타입으로 가져오기\n",
    "#    → 이 G는 networkx 그래프 형태로, 노드마다 위경도(“y”, “x”) 속성을 가집니다.\n",
    "G = ox.graph_from_point(\n",
    "    (lat_center, lon_center),\n",
    "    dist=1000,             # 미터 단위 반경(1km)\n",
    "    network_type=\"drive\"   # 자동차 주행용 도로만 추출\n",
    ")\n",
    "\n",
    "# (3) 각 센서(VEHICLE_ID)에 대해, 가장 가까운 도로망 상의 노드(노드 ID)를 찾기\n",
    "#     이때 scikit-learn이 반드시 설치되어 있어야 합니다.\n",
    "#     (예: pip install scikit-learn)\n",
    "sensor_nodes = {}\n",
    "for vid, row in rep.set_index(\"VEHICLE_ID\").iterrows():\n",
    "    lon, lat = row[\"LONGITUDE\"], row[\"LATITUDE\"]\n",
    "    # osmnx.distance.nearest_nodes는 “G”, “X경도”, “Y위도” 순서로 인자 사용\n",
    "    nearest_node = ox.distance.nearest_nodes(G, lon, lat)\n",
    "    sensor_nodes[vid] = nearest_node\n",
    "\n",
    "# (4) 센서 노드 ID(도로망 노드) → 0..N−1 인덱스로 변환\n",
    "sensor_nodes_idx = {vid: vid2idx[vid] for vid in vehicle_ids}\n",
    "\n",
    "#  예를 들어, \n",
    "#     센서 vid = 34AF2943 → 실제 도로망 노드 e.g. 345678901 노드 ID → 이 센서가 vid2idx[34AF2943] = 0번 인덱스로 매핑\n",
    "#     sensor_nodes : { \"34AF2943\": 345678901, ... }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594bedcd-ea5a-4771-bde2-2f1573c35867",
   "metadata": {},
   "source": [
    "#### sensor_nodes에는 VEHICLE_ID → 그래프 G의 노드 ID가 정의되어 있습니다.\n",
    "- 이 정보를 바탕으로 “노드 간 인접 리스트(edge_index)”를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98287e91-bdf9-4eb6-9954-fe0b9913cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노드 수: 1993, 엣지 수: 887459\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# vid2idx: VEHICLE_ID → 0..N−1\n",
    "# sensor_nodes: VEHICLE_ID → 실제 도로망 G 노드 ID\n",
    "# G: networkx 그래프\n",
    "\n",
    "edges_src = []\n",
    "edges_dst = []\n",
    "for vid_i, node_i in sensor_nodes.items():\n",
    "    idx_i = vid2idx[vid_i]\n",
    "    for vid_j, node_j in sensor_nodes.items():\n",
    "        idx_j = vid2idx[vid_j]\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "        try:\n",
    "            dist_m = nx.shortest_path_length(G, node_i, node_j, weight=\"length\")\n",
    "            if dist_m < 200:  # 200m 이내면 인접으로 간주\n",
    "                edges_src.append(idx_i)\n",
    "                edges_dst.append(idx_j)\n",
    "        except nx.NetworkXNoPath:\n",
    "            pass\n",
    "\n",
    "edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)  # shape: [2, E]\n",
    "print(f\"노드 수: {N}, 엣지 수: {edge_index.size(1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e3a4c-1b9b-4598-889e-662b0c0186f0",
   "metadata": {},
   "source": [
    "#### “동적 피처”(x_dyn) 만들기: 5분 윈도우 리샘플링 후 속도·가속·제동 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a08511d-01f2-4773-b2ae-ab1ec75510a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 우선 df_all에 timestamp가 datetime 타입으로 이미 들어 있다고 가정\n",
    "#     (위 코드에서 Parquet을 만들 때 pd.to_datetime을 거쳤습니다.)\n",
    "\n",
    "# (2) VEHICLE_ID별로 그룹화 + 5분 단위 리샘플링\n",
    "#     우리가 필요로 하는 건, 각 5분 윈도우마다\n",
    "#       - 평균 속도(mean of SPEED)\n",
    "#       - 평균 가속(mean of ACC_SEC)\n",
    "#       - 제동 횟수 혹은 제동 합계(sum of BRAKE_STATUS)\n",
    "#     등으로 동적 피처를 요약한 타임스텝별 테이블\n",
    "df_all = df_all.set_index(\"timestamp\")\n",
    "\n",
    "# 예시: dyn_df 라는 DataFrame을 만듭니다.\n",
    "#  index: 타임스텝(datetime index, 5분 간격)\n",
    "#  columns: MultiIndex (VEHICLE_ID, [SPEED_mean, ACC_SEC_mean, BRAKE_STATUS_sum])\n",
    "dyn_list = []\n",
    "for vid in vehicle_ids:\n",
    "    df_vid = df_all[df_all[\"VEHICLE_ID\"] == vid]\n",
    "    # 속도 평균, 가속 평균, 제동 합계\n",
    "    df_resampled = df_vid.resample(\"5min\").agg({\n",
    "        \"SPEED\": \"mean\",\n",
    "        \"ACC_SEC\": \"mean\",\n",
    "        \"BRAKE_STATUS\": \"sum\"\n",
    "    })\n",
    "    # 재색인하여 모든 타임스텝(5분 간격)에서 NaN을 허용하게 만들고, 뒤에서 0으로 채워 줘도 됩니다.\n",
    "    dyn_list.append(df_resampled)\n",
    "\n",
    "# 각 차량별로 resample된 DataFrame을 concat → MultiIndex columns\n",
    "dyn_df = pd.concat(dyn_list, axis=1, keys=vehicle_ids)\n",
    "\n",
    "# dyn_df의 인덱스(timestamps) 리스트\n",
    "times = dyn_df.index.to_pydatetime().tolist()\n",
    "T = len(times)  # 총 타임스텝 개수 (예: 하루 24*12 = 288개)\n",
    "\n",
    "# (3) “N x T x F_d” 텐서를 만들어서 PyTorch Tensor로 변환\n",
    "#       F_d = 3 (speed, acc, brake)\n",
    "import numpy as np\n",
    "\n",
    "# 미리 0으로 초기화\n",
    "x_dyn_np = np.zeros((T, N, 3), dtype=np.float32)\n",
    "\n",
    "for i_vid, vid in enumerate(vehicle_ids):\n",
    "    sub = dyn_df[vid]  \n",
    "    # sub는 columns=[\"SPEED\", \"ACC_SEC\", \"BRAKE_STATUS\"]\n",
    "    # NaN이 있을 경우 0으로 채워 주는 것이 일반적입니다.\n",
    "    sub = sub.fillna(0.0)\n",
    "    # 이제 sub.values.shape == (T, 3)\n",
    "    x_dyn_np[:, i_vid, 0] = sub[\"SPEED\"].values\n",
    "    x_dyn_np[:, i_vid, 1] = sub[\"ACC_SEC\"].values\n",
    "    x_dyn_np[:, i_vid, 2] = sub[\"BRAKE_STATUS\"].values\n",
    "\n",
    "# 최종 PyTorch 텐서\n",
    "x_dyn = torch.from_numpy(x_dyn_np)  # shape [T, N, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e710cb-340d-46f8-996a-0ba174fb8cbb",
   "metadata": {},
   "source": [
    "#### (선택) “정적 피처”(x_static)을 추가하고 싶다면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65fdc3-dc97-4a6e-9fba-380acccb3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_static_np = np.zeros((N, 2), dtype=np.float32)  # [N, 2] shape\n",
    "for i_vid, vid in enumerate(vehicle_ids):\n",
    "    row = rep[rep[\"VEHICLE_ID\"] == vid].iloc[0]\n",
    "    x_static_np[i_vid, 0] = row[\"LATITUDE\"]\n",
    "    x_static_np[i_vid, 1] = row[\"LONGITUDE\"]\n",
    "\n",
    "x_static = torch.from_numpy(x_static_np)  # [N, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d08a8-0572-471b-8522-3e358c557aec",
   "metadata": {},
   "source": [
    "#### PyTorch Dataset/DataLoader 만들기\n",
    "- 위에서 만들어 둔 x_dyn, x_static, edge_index를 직접 래핑하여 Dataset을 구현하면 .pt 파일 없이도 바로 학습이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe20803b-65cd-4129-be4b-5ba82cd05887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dyn      → (64, 10, 726, 3)\n",
      "x_static   → (64, 726, 5)\n",
      "edge_index → (64, 2, 1452)\n",
      "y          → (64, 3, 726, 3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpatioTemporalDataset(Dataset):\n",
    "    def __init__(self, x_dyn, x_static, edge_index, seq_len, pre_len):\n",
    "        \"\"\"\n",
    "        x_dyn      : torch.Tensor, shape [T, N, Fd]\n",
    "                     → 동적 피처 (예: Fd=3: [SPEED, ACC_SEC, BRAKE_STATUS] 등)\n",
    "        x_static   : torch.Tensor, shape [N, Fs]\n",
    "                     → 정적 피처 (예: POI 정보, 노드별 속성 등)\n",
    "        edge_index : torch.LongTensor, shape [2, E]\n",
    "                     → GNN 에 넣을 엣지 인덱스\n",
    "        seq_len    : int → 입력 시퀀스 길이 (예: 10)\n",
    "        pre_len    : int → 예측할 미래 길이 (예: 3)\n",
    "        \"\"\"\n",
    "        self.x_dyn      = x_dyn      # [T, N, Fd]\n",
    "        self.x_static   = x_static   # [N, Fs]\n",
    "        self.edge_index = edge_index # [2, E]\n",
    "        \n",
    "        T, N, Fd = x_dyn.shape\n",
    "\n",
    "        # sliding window로 X, Y (입력, 정답) 시퀀스 생성\n",
    "        X_list = []\n",
    "        Y_list = []\n",
    "        for t in range(T - seq_len - pre_len + 1):\n",
    "            # 입력 구간: t ~ t + seq_len - 1\n",
    "            # → shape [seq_len, N, Fd]\n",
    "            seq_X = x_dyn[t : t + seq_len]\n",
    "            # 예측 정답 구간: t+seq_len ~ t+seq_len+pre_len-1\n",
    "            # → shape [pre_len, N, Fd]\n",
    "            seq_Y = x_dyn[t + seq_len : t + seq_len + pre_len]\n",
    "\n",
    "            X_list.append(seq_X)\n",
    "            Y_list.append(seq_Y)\n",
    "\n",
    "        # [S, seq_len, N, Fd],  [S, pre_len, N, Fd] 로 저장\n",
    "        self.X = torch.stack(X_list, dim=0)  # [S, seq_len, N, Fd]\n",
    "        self.Y = torch.stack(Y_list, dim=0)  # [S, pre_len, N, Fd]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x_dyn'     : self.X[idx],        # [seq_len, N, Fd]\n",
    "            'x_static'  : self.x_static,      # [N, Fs]\n",
    "            'edge_index': self.edge_index,    # [2, E]\n",
    "            'y'         : self.Y[idx]         # [pre_len, N, Fd]\n",
    "        }\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "#  예시: DataLoader 생성 및 배치 확인\n",
    "if __name__ == '__main__':\n",
    "    # (1) 여기에 미리 준비된 텐서들을 넣어 주세요.\n",
    "    # 예를 들어:\n",
    "    #   x_dyn:  torch.randn(T, N, Fd)\n",
    "    #   x_static: torch.randn(N, Fs)\n",
    "    #   edge_index: torch.tensor([[0,1,2,...],[1,2,3,...]], dtype=torch.long)\n",
    "    #\n",
    "    # 아래는 더미 데이터를 만드는 예시입니다.\n",
    "    T, N, Fd = 200, 726, 3   # 예를 들어: T=200 timesteps, N=726 노드, Fd=3 채널\n",
    "    Fs = 5                   # 예를 들어 정적 피처 차원 Fs=5\n",
    "    seq_len   = 10           # 입력 시퀀스 길이\n",
    "    pre_len   = 3            # 예측 시퀀스 길이\n",
    "    batch_size = 64\n",
    "\n",
    "    # 더미 동적 피처 (예시: SPEED, ACC_SEC, BRAKE_STATUS)\n",
    "    x_dyn = torch.randn(T, N, Fd)\n",
    "    # 더미 정적 피처\n",
    "    x_static = torch.randn(N, Fs)\n",
    "    # 더미 엣지 인덱스 (임의로 만들어봄)\n",
    "    edge_index = torch.randint(0, N, (2, N*2), dtype=torch.long)\n",
    "\n",
    "    # Dataset/Loader 생성\n",
    "    dataset = SpatioTemporalDataset(\n",
    "        x_dyn      = x_dyn,\n",
    "        x_static   = x_static,\n",
    "        edge_index = edge_index,\n",
    "        seq_len    = seq_len,\n",
    "        pre_len    = pre_len\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 한 배치 꺼내 보기\n",
    "    batch = next(iter(loader))\n",
    "    for k, v in batch.items():\n",
    "        print(f\"{k:10} → {tuple(v.shape)}\")\n",
    "    # 출력 예:\n",
    "    #   x_dyn      → (64, 10, 726, 3)\n",
    "    #   x_static   → (726, 5)\n",
    "    #   edge_index → (2, ???)\n",
    "    #   y          → (64, 3, 726, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc3ab5-c9fd-44b9-b70a-c2d16c461292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
