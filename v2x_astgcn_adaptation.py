#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
V2X ë°ì´í„°ë¥¼ AST-GCN ë…¼ë¬¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì…ë ¥:
- data/daily_merged/8ì›”/220801_C_raw.csv (V2X ì£¼í–‰ ë°ì´í„°)
- data/daily_merged/8ì›”/220801_C_label.jsonl (V2X ë¼ë²¨ ë°ì´í„°)

ì¶œë ¥:
- v2x_astgcn_data/v2x_speed.csv     (ì‹œê°„Ã—ì°¨ëŸ‰ ì†ë„í–‰ë ¬)
- v2x_astgcn_data/v2x_adj.csv       (ì°¨ëŸ‰Ã—ì°¨ëŸ‰ ì¸ì ‘í–‰ë ¬)
- v2x_astgcn_data/v2x_poi.csv       (ì°¨ëŸ‰ë³„ ì •ì  ì†ì„±)
- v2x_astgcn_data/v2x_weather.csv   (ì‹œê°„ë³„ ë™ì  ì†ì„±)

Author: Claude (Anthropic)
Date: 2025-06-03
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

def load_v2x_data(data_dir):
    """
    V2X ì›ë³¸ ë°ì´í„° ë¡œë”© (ëª¨ë“  íŒŒì¼)
    
    Args:
        data_dir (str): V2X ë°ì´í„° í´ë” ê²½ë¡œ (ì˜ˆ: "data/daily_merged/8ì›”")
    
    Returns:
        raw_df (DataFrame): ëª¨ë“  ì£¼í–‰ ë°ì´í„° í•©ì³ì§„ ê²ƒ
        label_data (list): ëª¨ë“  ë¼ë²¨ ë°ì´í„° í•©ì³ì§„ ê²ƒ
    """
    print(f"ğŸ“‚ V2X ë°ì´í„° ë¡œë”©: {data_dir}")
    
    # 1. ëª¨ë“  ì£¼í–‰ ë°ì´í„° ë¡œë”©
    raw_files = [f for f in os.listdir(data_dir) if f.endswith('_raw.csv')]
    if not raw_files:
        raise FileNotFoundError(f"âŒ {data_dir}ì—ì„œ *_raw.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    print(f"   ğŸ“„ ë°œê²¬ëœ ì£¼í–‰ ë°ì´í„° íŒŒì¼: {len(raw_files)}ê°œ")
    
    # ëª¨ë“  raw íŒŒì¼ì„ í•©ì¹˜ê¸°
    all_raw_data = []
    for raw_file in raw_files:
        file_path = os.path.join(data_dir, raw_file)
        try:
            df = pd.read_csv(file_path)
            all_raw_data.append(df)
            print(f"       âœ… {raw_file}: {df.shape}")
        except Exception as e:
            print(f"       âŒ {raw_file} ë¡œë”© ì‹¤íŒ¨: {e}")
    
    # ëª¨ë“  ë°ì´í„° í•©ì¹˜ê¸°
    if all_raw_data:
        raw_df = pd.concat(all_raw_data, ignore_index=True)
        print(f"   ğŸ“Š í†µí•© ì£¼í–‰ ë°ì´í„°: {raw_df.shape}")
    else:
        raise ValueError("âŒ ë¡œë”©ëœ ì£¼í–‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    # 2. ëª¨ë“  ë¼ë²¨ ë°ì´í„° ë¡œë”©
    label_files = [f for f in os.listdir(data_dir) if f.endswith('_label.jsonl')]
    label_data = []
    
    if label_files:
        print(f"   ğŸ“„ ë°œê²¬ëœ ë¼ë²¨ ë°ì´í„° íŒŒì¼: {len(label_files)}ê°œ")
        
        for label_file in label_files:
            file_path = os.path.join(data_dir, label_file)
            try:
                with open(file_path, 'r') as f:
                    file_labels = []
                    for line in f:
                        file_labels.append(json.loads(line.strip()))
                    label_data.extend(file_labels)
                    print(f"       âœ… {label_file}: {len(file_labels)}ê°œ")
            except Exception as e:
                print(f"       âŒ {label_file} ë¡œë”© ì‹¤íŒ¨: {e}")
        
        print(f"   ğŸ“Š í†µí•© ë¼ë²¨ ë°ì´í„°: {len(label_data)}ê°œ")
    else:
        print("   âš ï¸ ë¼ë²¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    return raw_df, label_data

def create_time_vehicle_matrix(raw_df, time_interval='15min'):
    """
    V2X ë°ì´í„°ë¥¼ ì‹œê°„Ã—ì°¨ëŸ‰ ì†ë„ í–‰ë ¬ë¡œ ë³€í™˜
    """
    print(f"â° ì‹œê°„Ã—ì°¨ëŸ‰ í–‰ë ¬ ìƒì„± (ê°„ê²©: {time_interval})")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ë§¤í•‘
    print(f"   ğŸ” ì›ë³¸ ì»¬ëŸ¼ë“¤: {raw_df.columns.tolist()}")
    
    # 1. TRIP_ID ë§¤í•‘
    if 'TRIP_ID' not in raw_df.columns:
        if 'VEHICLE_ID' in raw_df.columns:
            raw_df['TRIP_ID'] = raw_df['VEHICLE_ID']
            print(f"   âœ… VEHICLE_ID â†’ TRIP_ID ë§¤í•‘")
        else:
            print(f"   âŒ ì°¨ëŸ‰ ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # 2. SPEED í™•ì¸
    if 'SPEED' not in raw_df.columns:
        for alt_col in ['speed', 'Speed', 'velocity', 'VELOCITY']:
            if alt_col in raw_df.columns:
                raw_df['SPEED'] = raw_df[alt_col]
                print(f"   âœ… {alt_col} â†’ SPEED ë§¤í•‘")
                break
        else:
            print(f"   âŒ ì†ë„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # 3. ì‹œê°„ ì»¬ëŸ¼ í™•ì¸ (ì´ ë¶€ë¶„ì´ í•µì‹¬!)
    time_column = None
    if 'ISSUE_DATE' in raw_df.columns:
        time_column = 'ISSUE_DATE'
        print(f"   âœ… ì‹œê°„ ì»¬ëŸ¼ ë°œê²¬: ISSUE_DATE")
    elif 'TIMESTAMP' in raw_df.columns:
        time_column = 'TIMESTAMP'
        print(f"   âœ… ì‹œê°„ ì»¬ëŸ¼ ë°œê²¬: TIMESTAMP")
    else:
        for alt_col in ['timestamp', 'time', 'TIME', 'datetime']:
            if alt_col in raw_df.columns:
                time_column = alt_col
                print(f"   âœ… ì‹œê°„ ì»¬ëŸ¼ ë°œê²¬: {alt_col}")
                break
        else:
            print(f"   âŒ ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ì‹œê°„ íŒŒì‹±
    if time_column:
        print(f"   ğŸ” ì‹œê°„ ì»¬ëŸ¼: {time_column}")
        print(f"   ğŸ” {time_column} íƒ€ì…: {raw_df[time_column].dtype}")
        print(f"   ğŸ” {time_column} ìƒ˜í”Œ: {raw_df[time_column].head().tolist()}")
        
        try:
            # ISSUE_DATE í˜•ì‹: 20220808170730 (YYYYMMDDHHMMSS)
            if time_column == 'ISSUE_DATE':
                # int64ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì‹±
                if raw_df[time_column].dtype in ['int64', 'float64']:
                    raw_df['datetime'] = pd.to_datetime(raw_df[time_column].astype(str), format='%Y%m%d%H%M%S', errors='coerce')
                else:
                    raw_df['datetime'] = pd.to_datetime(raw_df[time_column], format='%Y%m%d%H%M%S', errors='coerce')
            else:
                # ë‹¤ë¥¸ ì‹œê°„ í˜•ì‹ë“¤
                raw_df['datetime'] = pd.to_datetime(raw_df[time_column], errors='coerce')
            
            # íŒŒì‹± ì‹¤íŒ¨í•œ í–‰ë“¤ í™•ì¸
            failed_parsing = raw_df['datetime'].isna().sum()
            if failed_parsing > 0:
                print(f"   âš ï¸ íŒŒì‹± ì‹¤íŒ¨í•œ í–‰: {failed_parsing}ê°œ (ì „ì²´ì˜ {failed_parsing/len(raw_df)*100:.2f}%)")
                # ì‹¤íŒ¨í•œ í–‰ë“¤ì€ ì œê±°
                raw_df = raw_df.dropna(subset=['datetime'])
            
            if len(raw_df) > 0:
                print(f"   âœ… {time_column} íŒŒì‹± ì„±ê³µ: {raw_df['datetime'].min()} ~ {raw_df['datetime'].max()}")
                print(f"   ğŸ“Š ìœ íš¨í•œ ë°ì´í„°: {len(raw_df)}í–‰")
            else:
                raise ValueError(f"ëª¨ë“  {time_column} íŒŒì‹±ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"   âŒ {time_column} íŒŒì‹± ì‹¤íŒ¨: {e}")
            print("   â†’ 8ì›” ë‚´ ì‹œê°„ìœ¼ë¡œ ë¶„ì‚° ìƒì„±")
            start_date = pd.Timestamp('2022-08-01')
            end_date = pd.Timestamp('2022-08-31 23:59:59')
            raw_df['datetime'] = pd.date_range(start_date, end_date, periods=len(raw_df))
    else:
        print("   âš ï¸ ì‹œê°„ ì»¬ëŸ¼ ì—†ìŒ, 8ì›” ë‚´ ì‹œê°„ìœ¼ë¡œ ë¶„ì‚° ìƒì„±")
        start_date = pd.Timestamp('2022-08-01')
        end_date = pd.Timestamp('2022-08-31 23:59:59')
        raw_df['datetime'] = pd.date_range(start_date, end_date, periods=len(raw_df))
    
    # ì‹œê°„ ê°„ê²©ë³„ ê·¸ë£¹í™”
    raw_df['time_bin'] = raw_df['datetime'].dt.floor(time_interval)
    
    # ì°¨ëŸ‰ë³„ ì‹œê°„ëŒ€ë³„ í‰ê·  ì†ë„ ê³„ì‚°
    speed_pivot = raw_df.groupby(['time_bin', 'TRIP_ID'])['SPEED'].mean().unstack(fill_value=0)
    
    print(f"   âœ… í–‰ë ¬ í¬ê¸°: {speed_pivot.shape} (ì‹œê°„ Ã— ì°¨ëŸ‰)")
    print(f"   ğŸ“Š ì‹œê°„ ë²”ìœ„: {speed_pivot.index.min()} ~ {speed_pivot.index.max()}")
    print(f"   ğŸš— ì°¨ëŸ‰ ìˆ˜: {speed_pivot.shape[1]}ê°œ")
    
    return speed_pivot.values, list(speed_pivot.columns), list(speed_pivot.index)

def create_adjacency_matrix(raw_df, vehicle_ids, distance_threshold=500):
    """
    ì°¨ëŸ‰ ê°„ ì¸ì ‘í–‰ë ¬ ìƒì„± (ê±°ë¦¬ ê¸°ë°˜)
    
    Args:
        raw_df (DataFrame): V2X ì£¼í–‰ ë°ì´í„°
        vehicle_ids (list): ì°¨ëŸ‰ ID ëª©ë¡
        distance_threshold (float): ì¸ì ‘ ê¸°ì¤€ ê±°ë¦¬ (ë¯¸í„°)
    
    Returns:
        adj_matrix (ndarray): [num_vehicles, num_vehicles] ì¸ì ‘í–‰ë ¬
    """
    print(f"ğŸ—ºï¸ ì¸ì ‘í–‰ë ¬ ìƒì„± (ê±°ë¦¬ ì„ê³„ê°’: {distance_threshold}m)")
    
    num_vehicles = len(vehicle_ids)
    adj_matrix = np.zeros((num_vehicles, num_vehicles))
    
    # ì°¨ëŸ‰ë³„ í‰ê·  ìœ„ì¹˜ ê³„ì‚°
    if 'LONGITUDE' in raw_df.columns and 'LATITUDE' in raw_df.columns:
        vehicle_positions = {}
        
        for i, vid in enumerate(vehicle_ids):
            vehicle_data = raw_df[raw_df['TRIP_ID'] == vid]
            if len(vehicle_data) > 0:
                avg_lon = vehicle_data['LONGITUDE'].mean()
                avg_lat = vehicle_data['LATITUDE'].mean()
                vehicle_positions[i] = (avg_lon, avg_lat)
        
        # ì°¨ëŸ‰ ê°„ ê±°ë¦¬ ê³„ì‚° ë° ì¸ì ‘í–‰ë ¬ êµ¬ì„±
        for i in range(num_vehicles):
            for j in range(num_vehicles):
                if i != j and i in vehicle_positions and j in vehicle_positions:
                    # ë‹¨ìˆœ ìœ í´ë¦¬ë“œ ê±°ë¦¬ (ì‹¤ì œë¡œëŠ” ì§€êµ¬ ê±°ë¦¬ ê³„ì‚° í•„ìš”)
                    pos_i = vehicle_positions[i]
                    pos_j = vehicle_positions[j]
                    distance = np.sqrt((pos_i[0] - pos_j[0])**2 + (pos_i[1] - pos_j[1])**2) * 111000  # ëŒ€ëµì  ê±°ë¦¬ ë³€í™˜
                    
                    if distance < distance_threshold:
                        adj_matrix[i, j] = np.exp(-distance / distance_threshold)  # ê°€ì¤‘ì¹˜
        
        # ìê¸° ìì‹ ê³¼ì˜ ì—°ê²°
        np.fill_diagonal(adj_matrix, 1.0)
        
        connection_ratio = np.count_nonzero(adj_matrix) / (num_vehicles * num_vehicles)
        print(f"   âœ… ì¸ì ‘í–‰ë ¬ ì™„ì„±: {num_vehicles}Ã—{num_vehicles}")
        print(f"   ğŸ“Š ì—°ê²° ë¹„ìœ¨: {connection_ratio:.3f}")
        
    else:
        print("   âš ï¸ ìœ„ì¹˜ ì •ë³´ ì—†ìŒ, ì™„ì „ì—°ê²° ê·¸ë˜í”„ë¡œ ìƒì„±")
        adj_matrix = np.ones((num_vehicles, num_vehicles))
    
    return adj_matrix

def create_poi_features(raw_df, label_data, vehicle_ids):
    """
    ì°¨ëŸ‰ë³„ ì •ì  ì†ì„± (POI ì—­í• ) ìƒì„±
    
    Args:
        raw_df (DataFrame): V2X ì£¼í–‰ ë°ì´í„°
        label_data (list): V2X ë¼ë²¨ ë°ì´í„°
        vehicle_ids (list): ì°¨ëŸ‰ ID ëª©ë¡
    
    Returns:
        poi_matrix (ndarray): [num_vehicles, num_features] ì •ì  ì†ì„± í–‰ë ¬
    """
    print("ğŸ¢ ì°¨ëŸ‰ë³„ ì •ì  ì†ì„± (POI) ìƒì„±")
    
    num_vehicles = len(vehicle_ids)
    poi_features = []
    
    # ë¼ë²¨ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    label_dict = {}
    for label in label_data:
        if 'TRIP_ID' in label:
            label_dict[label['TRIP_ID']] = label
    
    for i, vid in enumerate(vehicle_ids):
        vehicle_data = raw_df[raw_df['TRIP_ID'] == vid]
        label_info = label_dict.get(vid, {})
        
        features = []
        
        # 1. ì£¼í–‰ íŒ¨í„´ íŠ¹ì„±
        if len(vehicle_data) > 0:
            features.append(vehicle_data['SPEED'].mean())           # í‰ê·  ì†ë„
            features.append(vehicle_data['SPEED'].std())            # ì†ë„ ë³€ë™ì„±
            features.append(vehicle_data['SPEED'].max())            # ìµœëŒ€ ì†ë„
            features.append(vehicle_data['SPEED'].min())            # ìµœì†Œ ì†ë„
        else:
            features.extend([30.0, 10.0, 60.0, 0.0])  # ê¸°ë³¸ê°’
        
        # 2. ìœ„ì¹˜ íŠ¹ì„±
        if 'LONGITUDE' in vehicle_data.columns and len(vehicle_data) > 0:
            features.append(vehicle_data['LONGITUDE'].mean())       # í‰ê·  ê²½ë„
            features.append(vehicle_data['LATITUDE'].mean())        # í‰ê·  ìœ„ë„
            features.append(vehicle_data['LONGITUDE'].std())        # ìœ„ì¹˜ ë³€ë™ì„± (ê²½ë„)
            features.append(vehicle_data['LATITUDE'].std())         # ìœ„ì¹˜ ë³€ë™ì„± (ìœ„ë„)
        else:
            features.extend([127.0, 37.0, 0.01, 0.01])  # ì„œìš¸ ê¸°ë³¸ê°’
        
        # 3. ë¼ë²¨ ê¸°ë°˜ í–‰ë™ íŠ¹ì„±
        turn_pref = 0.5  # ê¸°ë³¸ê°’
        if 'Turn' in label_info:
            if label_info['Turn'] == 'Right':
                turn_pref = 1.0
            elif label_info['Turn'] == 'Left':
                turn_pref = 0.0
        features.append(turn_pref)  # íšŒì „ ì„ í˜¸ë„
        
        lane_pref = 0.5  # ê¸°ë³¸ê°’
        if 'Lane' in label_info:
            if label_info['Lane'] == 'R-Side':
                lane_pref = 1.0
            elif label_info['Lane'] == 'L-Side':
                lane_pref = 0.0
        features.append(lane_pref)  # ì°¨ì„  ì„ í˜¸ë„
        
        speed_violation = 0.0
        if 'Speed' in label_info:
            speed_violation = 1.0 if label_info['Speed'] == 'True' else 0.0
        features.append(speed_violation)  # ì†ë„ ìœ„ë°˜ ì´ë ¥
        
        hazard_exp = 0.0
        if 'Hazard' in label_info:
            hazard_exp = 1.0 if label_info['Hazard'] == 'True' else 0.0
        features.append(hazard_exp)  # ìœ„í—˜ ìƒí™© ê²½í—˜
        
        poi_features.append(features)
    
    poi_matrix = np.array(poi_features)
    print(f"   âœ… ì •ì  ì†ì„± ì™„ì„±: {poi_matrix.shape} (ì°¨ëŸ‰ Ã— íŠ¹ì„±)")
    print(f"   ğŸ“Š íŠ¹ì„± ëª©ë¡: [í‰ê· ì†ë„, ì†ë„ë³€ë™, ìµœëŒ€ì†ë„, ìµœì†Œì†ë„, í‰ê· ê²½ë„, í‰ê· ìœ„ë„, ê²½ë„ë³€ë™, ìœ„ë„ë³€ë™, íšŒì „ì„ í˜¸, ì°¨ì„ ì„ í˜¸, ì†ë„ìœ„ë°˜, ìœ„í—˜ê²½í—˜]")
    
    return poi_matrix

def create_weather_features(time_index):
    """
    ì‹œê°„ë³„ ë™ì  ì†ì„± (Weather ì—­í• ) ìƒì„±
    
    Args:
        time_index (list): ì‹œê°„ ì¸ë±ìŠ¤ ëª©ë¡
    
    Returns:
        weather_matrix (ndarray): [time_steps, num_features] ë™ì  ì†ì„± í–‰ë ¬
    """
    print("ğŸŒ¤ï¸ ì‹œê°„ë³„ ë™ì  ì†ì„± (Weather) ìƒì„±")
    
    weather_features = []
    
    for timestamp in time_index:
        features = []
        
        # 1. ì‹œê°„ íŒ¨í„´ (Period ì •ë³´)
        hour = timestamp.hour
        
        # Period ì›í•« ì¸ì½”ë”© (F/A/N/D)
        period_f = 1.0 if 6 <= hour < 12 else 0.0   # ì˜¤ì „ (06-12)
        period_a = 1.0 if 12 <= hour < 18 else 0.0  # ì˜¤í›„ (12-18)
        period_n = 1.0 if 18 <= hour < 24 else 0.0  # ë°¤ (18-24)
        period_d = 1.0 if 0 <= hour < 6 else 0.0    # ìƒˆë²½ (00-06)
        
        features.extend([period_f, period_a, period_n, period_d])
        
        # 2. ìš”ì¼ ì •ë³´
        weekday = timestamp.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
        is_weekend = 1.0 if weekday >= 5 else 0.0
        is_weekday = 1.0 - is_weekend
        
        features.extend([is_weekday, is_weekend])
        
        # 3. ì‹œê°„ëŒ€ë³„ êµí†µ íŒ¨í„´
        rush_morning = 1.0 if 7 <= hour <= 9 else 0.0    # ì¶œê·¼ ì‹œê°„
        rush_evening = 1.0 if 17 <= hour <= 19 else 0.0  # í‡´ê·¼ ì‹œê°„
        lunch_time = 1.0 if 11 <= hour <= 13 else 0.0    # ì ì‹¬ ì‹œê°„
        
        features.extend([rush_morning, rush_evening, lunch_time])
        
        # 4. ì¶”ê°€ ì‹œê°„ íŠ¹ì„±
        features.append(hour / 24.0)           # ì‹œê°„ (ì •ê·œí™”)
        features.append(weekday / 6.0)         # ìš”ì¼ (ì •ê·œí™”)
        features.append(timestamp.day / 31.0)  # ë‚ ì§œ (ì •ê·œí™”)
        
        # 5. ì‹œë®¬ë ˆì´ì…˜ëœ êµí†µ ì§€í‘œ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‹¤ì‹œê°„ ë°ì´í„° ì‚¬ìš©)
        # ì¶œí‡´ê·¼ ì‹œê°„ì— í˜¼ì¡ë„ ì¦ê°€
        traffic_density = 0.5
        if rush_morning or rush_evening:
            traffic_density = 0.8 + np.random.normal(0, 0.1)
        elif lunch_time:
            traffic_density = 0.6 + np.random.normal(0, 0.05)
        else:
            traffic_density = 0.3 + np.random.normal(0, 0.05)
        
        features.append(np.clip(traffic_density, 0, 1))
        
        # 6. ë„¤íŠ¸ì›Œí¬ ìƒíƒœ (V2X íŠ¹í™”)
        network_quality = 0.8 + np.random.normal(0, 0.1)  # í†µì‹  í’ˆì§ˆ
        features.append(np.clip(network_quality, 0, 1))
        
        weather_features.append(features)
    
    weather_matrix = np.array(weather_features)
    print(f"   âœ… ë™ì  ì†ì„± ì™„ì„±: {weather_matrix.shape} (ì‹œê°„ Ã— íŠ¹ì„±)")
    print(f"   ğŸ“Š íŠ¹ì„± ëª©ë¡: [Period_F, Period_A, Period_N, Period_D, í‰ì¼, ì£¼ë§, ì¶œê·¼ì‹œê°„, í‡´ê·¼ì‹œê°„, ì ì‹¬ì‹œê°„, ì‹œê°„ì •ê·œí™”, ìš”ì¼ì •ê·œí™”, ë‚ ì§œì •ê·œí™”, êµí†µë°€ë„, ë„¤íŠ¸ì›Œí¬í’ˆì§ˆ]")
    
    return weather_matrix

def save_astgcn_format(speed_matrix, adj_matrix, poi_matrix, weather_matrix, 
                       vehicle_ids, time_index, output_dir='v2x_astgcn_data'):
    """
    AST-GCN í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì €ì¥
    
    Args:
        speed_matrix (ndarray): ì†ë„ í–‰ë ¬
        adj_matrix (ndarray): ì¸ì ‘í–‰ë ¬
        poi_matrix (ndarray): ì •ì  ì†ì„± í–‰ë ¬
        weather_matrix (ndarray): ë™ì  ì†ì„± í–‰ë ¬
        vehicle_ids (list): ì°¨ëŸ‰ ID ëª©ë¡
        time_index (list): ì‹œê°„ ì¸ë±ìŠ¤ ëª©ë¡
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    print(f"ğŸ’¾ AST-GCN í˜•ì‹ ì €ì¥: {output_dir}")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ì†ë„ í–‰ë ¬ ì €ì¥ (CSV, header ì—†ìŒ)
    speed_df = pd.DataFrame(speed_matrix)
    speed_path = os.path.join(output_dir, 'v2x_speed.csv')
    speed_df.to_csv(speed_path, header=False, index=False)
    print(f"   âœ… {speed_path}: {speed_matrix.shape}")
    
    # 2. ì¸ì ‘í–‰ë ¬ ì €ì¥ (CSV, header ì—†ìŒ)
    adj_df = pd.DataFrame(adj_matrix)
    adj_path = os.path.join(output_dir, 'v2x_adj.csv')
    adj_df.to_csv(adj_path, header=False, index=False)
    print(f"   âœ… {adj_path}: {adj_matrix.shape}")
    
    # 3. ì •ì  ì†ì„± ì €ì¥ (CSV, header ì—†ìŒ)
    poi_df = pd.DataFrame(poi_matrix)
    poi_path = os.path.join(output_dir, 'v2x_poi.csv')
    poi_df.to_csv(poi_path, header=False, index=False)
    print(f"   âœ… {poi_path}: {poi_matrix.shape}")
    
    # 4. ë™ì  ì†ì„± ì €ì¥ (CSV, header ì—†ìŒ)
    weather_df = pd.DataFrame(weather_matrix)
    weather_path = os.path.join(output_dir, 'v2x_weather.csv')
    weather_df.to_csv(weather_path, header=False, index=False)
    print(f"   âœ… {weather_path}: {weather_matrix.shape}")
    
    # 5. ë©”íƒ€ë°ì´í„° ì €ì¥ (ì°¸ê³ ìš©)
    metadata = {
        'num_vehicles': len(vehicle_ids),
        'num_time_steps': len(time_index),
        'time_range': {
            'start': str(time_index[0]),
            'end': str(time_index[-1])
        },
        'vehicle_ids': vehicle_ids[:100],  # ì²˜ìŒ 100ê°œë§Œ ì €ì¥ (ìš©ëŸ‰ ë¬¸ì œ)
        'data_shapes': {
            'speed_matrix': speed_matrix.shape,
            'adj_matrix': adj_matrix.shape,
            'poi_matrix': poi_matrix.shape,
            'weather_matrix': weather_matrix.shape
        },
        'feature_info': {
            'poi_features': ['í‰ê· ì†ë„', 'ì†ë„ë³€ë™', 'ìµœëŒ€ì†ë„', 'ìµœì†Œì†ë„', 'í‰ê· ê²½ë„', 'í‰ê· ìœ„ë„', 
                           'ê²½ë„ë³€ë™', 'ìœ„ë„ë³€ë™', 'íšŒì „ì„ í˜¸', 'ì°¨ì„ ì„ í˜¸', 'ì†ë„ìœ„ë°˜', 'ìœ„í—˜ê²½í—˜'],
            'weather_features': ['Period_F', 'Period_A', 'Period_N', 'Period_D', 'í‰ì¼', 'ì£¼ë§',
                               'ì¶œê·¼ì‹œê°„', 'í‡´ê·¼ì‹œê°„', 'ì ì‹¬ì‹œê°„', 'ì‹œê°„ì •ê·œí™”', 'ìš”ì¼ì •ê·œí™”', 
                               'ë‚ ì§œì •ê·œí™”', 'êµí†µë°€ë„', 'ë„¤íŠ¸ì›Œí¬í’ˆì§ˆ']
        }
    }
    
    metadata_path = os.path.join(output_dir, 'metadata.json')
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print(f"   âœ… {metadata_path}: ë©”íƒ€ë°ì´í„°")

def convert_v2x_to_astgcn_format(data_dir='data/daily_merged/8ì›”', 
                                 output_dir='v2x_astgcn_data',
                                 time_interval='5min',
                                 distance_threshold=500):
    """
    V2X ë°ì´í„°ë¥¼ AST-GCN í˜•ì‹ìœ¼ë¡œ ì „ì²´ ë³€í™˜
    
    Args:
        data_dir (str): V2X ë°ì´í„° ë””ë ‰í† ë¦¬
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
        time_interval (str): ì‹œê°„ ê°„ê²©
        distance_threshold (float): ì¸ì ‘ ê±°ë¦¬ ì„ê³„ê°’
    
    Returns:
        tuple: (speed_matrix, poi_matrix, weather_matrix, adj_matrix, vehicle_ids)
    """
    print("=" * 60)
    print("ğŸš— V2X â†’ AST-GCN ë°ì´í„° ë³€í™˜ ì‹œì‘")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë”©
    raw_df, label_data = load_v2x_data(data_dir)
    
    # 2. ì‹œê°„Ã—ì°¨ëŸ‰ í–‰ë ¬ ìƒì„±
    speed_matrix, vehicle_ids, time_index = create_time_vehicle_matrix(raw_df, time_interval)
    
    # 3. ì¸ì ‘í–‰ë ¬ ìƒì„±
    adj_matrix = create_adjacency_matrix(raw_df, vehicle_ids, distance_threshold)
    
    # 4. ì •ì  ì†ì„± ìƒì„±
    poi_matrix = create_poi_features(raw_df, label_data, vehicle_ids)
    
    # 5. ë™ì  ì†ì„± ìƒì„±
    weather_matrix = create_weather_features(time_index)
    
    # 6. AST-GCN í˜•ì‹ìœ¼ë¡œ ì €ì¥
    save_astgcn_format(speed_matrix, adj_matrix, poi_matrix, weather_matrix,
                       vehicle_ids, time_index, output_dir)
    
    print("=" * 60)
    print("âœ… V2X â†’ AST-GCN ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“‚ ì¶œë ¥ ìœ„ì¹˜: {output_dir}")
    print(f"ğŸ“Š ë°ì´í„° ìš”ì•½:")
    print(f"   ğŸš— ì°¨ëŸ‰ ìˆ˜: {len(vehicle_ids)}")
    print(f"   â° ì‹œê°„ ìŠ¤í…: {len(time_index)}")
    print(f"   ğŸ¢ ì •ì  íŠ¹ì„±: {poi_matrix.shape[1]}ê°œ")
    print(f"   ğŸŒ¤ï¸ ë™ì  íŠ¹ì„±: {weather_matrix.shape[1]}ê°œ")
    print("=" * 60)
    
    return speed_matrix, poi_matrix, weather_matrix, adj_matrix, vehicle_ids

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # ì„¤ì • ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°
    DATA_DIR = "data/daily_merged/08ì›”"  # V2X ë°ì´í„° ê²½ë¡œ
    OUTPUT_DIR = "v2x_astgcn_data"     # ì¶œë ¥ í´ë”
    TIME_INTERVAL = "15min"             # ì‹œê°„ ê°„ê²© (5ë¶„)
    DISTANCE_THRESHOLD = 500           # ì¸ì ‘ ê±°ë¦¬ (500m)
    
    # V2X ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    if not os.path.exists(DATA_DIR):
        print(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}")
        print("ğŸ’¡ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•˜ì„¸ìš”:")
        print("   DATA_DIR = 'ì—¬ëŸ¬ë¶„ì˜/V2X/ë°ì´í„°/ê²½ë¡œ'")
        exit(1)
    
    try:
        # ë³€í™˜ ì‹¤í–‰
        speed_matrix, poi_matrix, weather_matrix, adj_matrix, vehicle_ids = convert_v2x_to_astgcn_format(
            data_dir=DATA_DIR,
            output_dir=OUTPUT_DIR,
            time_interval=TIME_INTERVAL,
            distance_threshold=DISTANCE_THRESHOLD
        )
        
        print("ğŸ‰ ë³€í™˜ ì„±ê³µ! ì´ì œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•˜ì„¸ìš”:")
        print("   1. acell.pyì—ì„œ load_v2x_data í•¨ìˆ˜ ì¶”ê°€")
        print("   2. main.pyì—ì„œ ë°ì´í„° ë¡œë”© ë¶€ë¶„ ìˆ˜ì •")
        print("   3. python main.py ì‹¤í–‰")
        
    except Exception as e:
        print(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ’¡ ì˜¤ë¥˜ í•´ê²° ë°©ë²•:")
        print("   1. ë°ì´í„° íŒŒì¼ ê²½ë¡œ í™•ì¸")
        print("   2. CSV íŒŒì¼ í˜•ì‹ í™•ì¸ (TRIP_ID, SPEED, TIMESTAMP ì»¬ëŸ¼)")
        print("   3. ê¶Œí•œ ë¬¸ì œ í™•ì¸")
        
        import traceback
        traceback.print_exc()